<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Main</title><link href="ocean.css" rel="stylesheet" type="text/css" title="Ocean" /><script src="haddock-util.js" type="text/javascript"></script><script type="text/javascript">//<![CDATA[
window.onload = function () {pageLoad();setSynopsis("mini_Main.html");};
//]]>
</script></head><body><div id="package-header"><ul class="links" id="page-menu"><li><a href="index.html">Contents</a></li><li><a href="doc-index.html">Index</a></li></ul><p class="caption empty">&nbsp;</p></div><div id="content"><div id="module-header"><table class="info"><tr><th>Safe Haskell</th><td>None</td></tr></table><p class="caption">Main</p></div><div id="synopsis"><p id="control.syn" class="caption expander" onclick="toggleSection('syn')">Synopsis</p><ul id="section.syn" class="hide" onclick="toggleSection('syn')"><li class="src short"><a href="#v:main">main</a> :: IO ()</li><li class="src short"><a href="#v:crawlSubdomain">crawlSubdomain</a> :: [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>] -&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>] -&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>] -&gt; IO [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</li><li class="src short"><a href="#v:crawlFailure">crawlFailure</a> :: [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>] -&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>] -&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>] -&gt; IO [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</li><li class="src short"><a href="#v:crawlSuccess">crawlSuccess</a> :: [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>] -&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>] -&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>] -&gt; ByteString -&gt; IO [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</li></ul></div><div id="interface"><h1>Documentation</h1><div class="top"><p class="src"><a name="v:main" class="def">main</a> :: IO ()</p><div class="doc"><p>Given URL as user input, crawls and pretty prints JSON of subdomain
   structure.</p></div></div><div class="top"><p class="src"><a name="v:crawlSubdomain" class="def">crawlSubdomain</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</td><td class="doc"><p>The accumulator for visited webpages</p></td></tr><tr><td class="src">-&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>]</td><td class="doc"><p>The accumulator for visited URLs</p></td></tr><tr><td class="src">-&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>]</td><td class="doc"><p>The list of URLs to still visit</p></td></tr><tr><td class="src">-&gt; IO [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</td><td class="doc"><p>Returns final list of visited webpages</p></td></tr></table></div><div class="doc"><p>Accumulates a list of unique visited webpages and URLs by crawling a given
   list of URLs.
   Prints update for each page crawled and for each page not found.
   Accumulators should usually be initiated as empty lists.</p></div></div><div class="top"><p class="src"><a name="v:crawlFailure" class="def">crawlFailure</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</td><td class="doc"><p>The list of visited webpages</p></td></tr><tr><td class="src">-&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>]</td><td class="doc"><p>The list of visited URLs</p></td></tr><tr><td class="src">-&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>]</td><td class="doc"><p>The list of this URL and URLs to still
   visit</p></td></tr><tr><td class="src">-&gt; IO [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</td><td class="doc"><p>Returns final list of visited webpages</p></td></tr></table></div><div class="doc"><p>Outputs a warning message with URL not reached and crawls remaining URLs
   with this URL marked as seen.
   There *must be at least one URL to still visit*.</p></div></div><div class="top"><p class="src"><a name="v:crawlSuccess" class="def">crawlSuccess</a></p><div class="subs arguments"><p class="caption">Arguments</p><table><tr><td class="src">:: [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</td><td class="doc"><p>The list of visited webpages</p></td></tr><tr><td class="src">-&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>]</td><td class="doc"><p>The list of visited URLs</p></td></tr><tr><td class="src">-&gt; [<a href="Utils-UrlParser.html#t:Url">Url</a>]</td><td class="doc"><p>The list of this URL and URLs to still
   visit</p></td></tr><tr><td class="src">-&gt; ByteString</td><td class="doc"><p>The source at this URL</p></td></tr><tr><td class="src">-&gt; IO [<a href="Utils-HtmlParser.html#t:Webpage">Webpage</a>]</td><td class="doc"><p>Returns final list of visited webpages</p></td></tr></table></div><div class="doc"><p>Outputs message with crawled URL, crawls and saves Webpage, marks URL as
   seen and crawls remaining URLs, including any URLs marked on this page.
   There *must be at least one URL to still visit*.</p></div></div></div></div><div id="footer"><p>Produced by <a href="http://www.haskell.org/haddock/">Haddock</a> version 2.16.1</p></div></body></html>